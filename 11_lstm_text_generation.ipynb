{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "11_lstm_text_generation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerberusv2px/nlp-learn/blob/main/11_lstm_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uTzybifXx5uJ"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from random import randint\n",
        "import re\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mZ-tCAZux5uR",
        "outputId": "010e3b7e-b76e-4a53-c7b8-e64336bd4ca3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg as gut\n",
        "\n",
        "print(gut.fileids())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DQVD6q_-x5uW"
      },
      "source": [
        "macbeth_text = nltk.corpus.gutenberg.raw('shakespeare-macbeth.txt')\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TCUhrENgx5uY",
        "outputId": "4bc2b0bc-3fb9-43a2-9015-67e900983a86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(macbeth_text[:500])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[The Tragedie of Macbeth by William Shakespeare 1603]\n",
            "\n",
            "\n",
            "Actus Primus. Scoena Prima.\n",
            "\n",
            "Thunder and Lightning. Enter three Witches.\n",
            "\n",
            "  1. When shall we three meet againe?\n",
            "In Thunder, Lightning, or in Raine?\n",
            "  2. When the Hurley-burley's done,\n",
            "When the Battaile's lost, and wonne\n",
            "\n",
            "   3. That will be ere the set of Sunne\n",
            "\n",
            "   1. Where the place?\n",
            "  2. Vpon the Heath\n",
            "\n",
            "   3. There to meet with Macbeth\n",
            "\n",
            "   1. I come, Gray-Malkin\n",
            "\n",
            "   All. Padock calls anon: faire is foule, and foule is faire,\n",
            "Houer through \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XnyKiSeux5uZ"
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9YbgwgOXx5ub",
        "outputId": "fad9bb8c-47bc-4dfd-d750-87a9e3ed97f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "macbeth_text = preprocess_text(macbeth_text)\n",
        "macbeth_text[:500]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' the tragedie of macbeth by william shakespeare actus primus scoena prima thunder and lightning enter three witches when shall we three meet againe in thunder lightning or in raine when the hurley burley done when the battaile lost and wonne that will be ere the set of sunne where the place vpon the heath there to meet with macbeth come gray malkin all padock calls anon faire is foule and foule is faire houer through the fogge and filthie ayre exeunt scena secunda alarum within enter king malcom'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "UtZNcQcAx5ud"
      },
      "source": [
        "### Convert Words into Numbers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kXmrpJYlx5ug",
        "outputId": "40d057c4-ed1f-4cd4-fa9c-d029fc8a2dde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "macbeth_text_words = word_tokenize(macbeth_text)\n",
        "n_words = len(macbeth_text_words)\n",
        "unique_words = len(set(macbeth_text_words))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B6auqU6sx5ui",
        "outputId": "d6d58516-9a0b-44aa-82ea-cc8222399fb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Total Words: %d' % n_words)\n",
        "print('Unique Words: %d' % unique_words)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Words: 17250\n",
            "Unique Words: 3436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AJ8-DQU5x5uk"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words=unique_words + 1)\n",
        "tokenizer.fit_on_texts(macbeth_text_words)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AUfAqdDCx5ul"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "word_2_index = tokenizer.word_index"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "je9n0CMox5um",
        "outputId": "70d8da5e-c8b5-459d-c8f8-590255af5c0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(macbeth_text_words[200])\n",
        "print(word_2_index[macbeth_text_words[200]])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "like\n",
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "yTi6E7b2x5uo"
      },
      "source": [
        "### Modifying the Shape of Data\n",
        "Text generation falls in the category of many-to-one sequence problems since the input is a sequence of words and output is a single word. We will be using the Long Short-Term Memory Network (LSTM), which is a type of recurrent neural network to create our text generation model. LSTM accepts data in a 3-dimensional format (number of samples, number of time-steps, features per time-step). Since the output will be a single word, the shape of the output will be 2-dimensional (number of samples, number of unique words in the corpus).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "VYcPXu00x5up"
      },
      "source": [
        "input_sequences = []\n",
        "output_words = []\n",
        "input_seq_length = 100\n",
        "\n",
        "for i in range(0, n_words - input_seq_length, 1):\n",
        "    in_seq = macbeth_text_words[i:i + input_seq_length]\n",
        "    out_seq = macbeth_text_words[i + input_seq_length]\n",
        "    input_sequences.append([word_2_index[word] for word in in_seq])\n",
        "    output_words.append(word_2_index[out_seq])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hhq7zVT9x5ur"
      },
      "source": [
        "In the script above, we declare two empty lists input_sequence and output_words. The input_seq_length is set to 100, which means that our input sequence will consist of 100 words. Next, we execute a loop where in the first iteration, integer values for the first 100 words from the text are appended to the input_sequence list. The 101st word is appended to the output_words list. During the second iteration, a sequence of words that starts from the 2nd word in the text and ends at the 101st word is stored in the input_sequence list, and the 102nd word is stored in the output_words array, and so on. A total of 17150 input sequences will be generated since there are 17250 total words in the dataset (100 less than the total words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hauY-INIx5us",
        "outputId": "58dc16bd-4813-4ee2-b590-7a50c3986424",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(input_sequences[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 869, 4, 40, 60, 1358, 1359, 408, 1360, 1361, 409, 265, 2, 870, 31, 190, 291, 76, 36, 30, 190, 327, 128, 8, 265, 870, 83, 8, 1362, 76, 1, 1363, 1364, 86, 76, 1, 1365, 354, 2, 871, 5, 34, 14, 168, 1, 292, 4, 649, 77, 1, 220, 41, 1, 872, 53, 3, 327, 12, 40, 52, 1366, 1367, 25, 1368, 873, 328, 355, 9, 410, 2, 410, 9, 355, 1369, 356, 1, 1370, 2, 874, 169, 103, 127, 411, 357, 149, 31, 51, 1371, 329, 107, 12, 358, 412, 875, 1372, 51, 20, 170, 92, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BRDhTeEFx5ut"
      },
      "source": [
        "normalize our input sequences by dividing the integers in the sequences by the largest integer value. The following script also converts the output into 2-dimensional format.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jlL6L86Nx5ut"
      },
      "source": [
        "X = np.reshape(input_sequences, (len(input_sequences), input_seq_length, 1))\n",
        "X = X / float(vocab_size)\n",
        "\n",
        "y = to_categorical(output_words)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ybYO079Wx5uu",
        "outputId": "6e61e5be-13c6-4dd5-a8f2-ad86780b32da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (17150, 100, 1)\n",
            "y shape: (17150, 3437)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "G8MNcbaLx5uv"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(800, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(800, return_sequences=True))\n",
        "model.add(LSTM(800))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DKu7dhRTx5uw",
        "outputId": "121e983a-c7e6-41ac-a6e1-c9984e2595d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 800)          2566400   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 800)          5123200   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 800)               5123200   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3437)              2753037   \n",
            "=================================================================\n",
            "Total params: 15,565,837\n",
            "Trainable params: 15,565,837\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "IYM6o6gdx5ux"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "JEcfovqKx5uy",
        "outputId": "0cca3c0d-0ef8-49dc-e305-b442b50392e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X, y, batch_size=64, epochs=10, verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "268/268 [==============================] - 44s 163ms/step - loss: 6.7646\n",
            "Epoch 2/10\n",
            "268/268 [==============================] - 45s 168ms/step - loss: 6.6684\n",
            "Epoch 3/10\n",
            "268/268 [==============================] - 47s 174ms/step - loss: 6.6304\n",
            "Epoch 4/10\n",
            "268/268 [==============================] - 48s 180ms/step - loss: 6.6184\n",
            "Epoch 5/10\n",
            "268/268 [==============================] - 49s 182ms/step - loss: 6.6093\n",
            "Epoch 6/10\n",
            "268/268 [==============================] - 49s 183ms/step - loss: 6.6054\n",
            "Epoch 7/10\n",
            "268/268 [==============================] - 49s 184ms/step - loss: 6.6034\n",
            "Epoch 8/10\n",
            "268/268 [==============================] - 50s 187ms/step - loss: 6.6068\n",
            "Epoch 9/10\n",
            "268/268 [==============================] - 50s 187ms/step - loss: 6.6003\n",
            "Epoch 10/10\n",
            "268/268 [==============================] - 50s 186ms/step - loss: 6.5985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9d03fc8c50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJOqa2qu0BBk"
      },
      "source": [
        "To make predictions, we will randomly select a sequence from the `input_sequence` list, convert it into a 3-dimentional shape and then pass it to the `predict()` method of the trained model. The model will return a one-hot encoded array where the index that contains 1 will be the index value of the next word. The index value is then passed to the `index_2_word` dictionary, where the word index is used as a key. The `index_2_word` dictionary will return the word that belong to the index that is passed as a key to the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4Ae_-AYLx5uz",
        "outputId": "97f790d8-7362-4137-ca6b-bdaeb00336cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "random_seq_index = np.random.randint(0, len(input_sequences)-1)\n",
        "random_seq = input_sequences[random_seq_index]\n",
        "\n",
        "index_2_word = dict(map(reversed, word_2_index.items()))\n",
        "\n",
        "word_sequence = [index_2_word[value] for value in random_seq]\n",
        "\n",
        "print(' '.join(word_sequence))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "from my sight and bid my will auouch it yet must not for certaine friends that are both his and mine whose loues may not drop but wayle his fall who my selfe struck downe and thence it is that to your assistance doe make loue masking the businesse from the common eye for sundry weightie reasons murth we shall my lord performe what you command vs murth though our liues macb your spirits shine through you within this houre at most will aduise you where to plant your selues acquaint you with the perfect spy th time the moment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nf-pXvS0OtX"
      },
      "source": [
        "for i in range(100):\n",
        "    int_sample = np.reshape(random_seq, (1, len(random_seq), 1))\n",
        "    int_sample = int_sample / float(vocab_size)\n",
        "\n",
        "    predicted_word_index = model.predict(int_sample, verbose=0)\n",
        "\n",
        "    predicted_word_id = np.argmax(predicted_word_index)\n",
        "    seq_in = [index_2_word[index] for index in random_seq]\n",
        "\n",
        "    word_sequence.append(index_2_word[ predicted_word_id])\n",
        "\n",
        "    random_seq.append(predicted_word_id)\n",
        "    random_seq = random_seq[1:len(random_seq)]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m45fMf4J0Se1",
        "outputId": "345f695b-df6a-47fb-b319-55afa8d30a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_output = \"\"\n",
        "for word in word_sequence:\n",
        "    final_output = final_output + \" \" + word\n",
        "\n",
        "print(final_output)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " from my sight and bid my will auouch it yet must not for certaine friends that are both his and mine whose loues may not drop but wayle his fall who my selfe struck downe and thence it is that to your assistance doe make loue masking the businesse from the common eye for sundry weightie reasons murth we shall my lord performe what you command vs murth though our liues macb your spirits shine through you within this houre at most will aduise you where to plant your selues acquaint you with the perfect spy th time the moment the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqf3nJQE0fkS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}